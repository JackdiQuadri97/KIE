resume_from_checkpoint_path: null # only used for resume_from_checkpoint option in PL
result_path: "./result"
pretrained_model_name_or_path: "naver-clova-ix/donut-base" # loading a pre-trained model (from moldehub or path)
dataset_name_or_paths: ["naver-clova-ix/cord-v2"] # loading datasets (from moldehub or path)
sort_json_key: False # cord dataset is preprocessed, and publicly available at https://huggingface.co/datasets/naver-clova-ix/cord-v2
train_batch_sizes: [1]
val_batch_sizes: [1]
input_size: [1280, 1600] # both need to be multiple of 320 apparently
max_length: 256
align_long_axis: False
num_nodes: 1
seed: 2022
lr: 3e-5
warmup_steps: 1000
num_training_samples_per_epoch: 10000
max_epochs: 2 #changed from standard 30 to test the output
max_steps: -1
num_workers: 4
val_check_interval: 1.0
check_val_every_n_epoch: 2
gradient_clip_val: 1.0
verbose: True